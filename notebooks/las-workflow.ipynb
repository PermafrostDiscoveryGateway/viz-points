{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice running the workflow through 3dtiles tiling\n",
    "\n",
    "- use environment with `viz-staging` and `viz-raster` installed\n",
    "- after running through these steps in chunks in this notebook, it's a great idea to transfer the code to a script and run as a `tmux` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory in which to look for data (change this to your needs!)\n",
    "DATA_DIR = '/home/shares/drp/pointcloud'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data import\n",
    "from pathlib import Path\n",
    "\n",
    "# py3dtiles\n",
    "from py3dtiles.tileset.utils import TileContentReader\n",
    "\n",
    "# interaction with the system\n",
    "import subprocess\n",
    "\n",
    "# logging\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the logging configuration\n",
    "\n",
    "This prints logging statements to a file specified by the path in the config. Change the filepath as needed. There will be many logging statements written to that file. It's helpful to ctrl + f for certain logged statements when troubleshooting. For example, if fewer files were staged than expected, you can search for \"error\" or \"failed\". If you are debugging a silent error and suspect that the issue has something to do with the order in which input files are processed, you can search for the input filenames to determine which was staged first. In between runs, it's a good idea to delete the log from the past run, rename it, or archive it elsewhere so the next run's log does not append to the same log file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FMT = '%Y-%m-%dT%H:%M:%S'\n",
    "LOG_FMT = \"%(asctime)s:%(levelname)s: %(message)s\" # overrides import\n",
    "L = logging.getLogger('DRPWorkflow')\n",
    "L.setLevel(\"INFO\")\n",
    "handler = logging.handlers.WatchedFileHandler(\n",
    "    os.environ.get(\"LOGFILE\", os.path.expanduser(\"~/bin/drpworkflow/log/log.log\"))) # <- note: should find this dir programatically in the future\n",
    "formatter = logging.Formatter(fmt=LOG_FMT, datefmt=DATE_FMT)\n",
    "handler.setFormatter(formatter)\n",
    "L.addHandler(handler)\n",
    "L.info(\"Logging start.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "In order to process 1 or 2 files instead of all 3 adjacent files on Wrangle Island, subset the `flist` list of filepaths created below. Estimated times and number of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/shares/drp/pointcloud/Site7.las']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path(DATA_DIR)\n",
    "vlrcorrect_dir = os.path.join(base_dir, 'vlrcorrect')\n",
    "archive_dir = os.path.join(base_dir, 'archive')\n",
    "out_dir = os.path.join(base_dir, '3dtiles')\n",
    "for d in [vlrcorrect_dir, archive_dir, out_dir]:\n",
    "    L.info('Creating dir %s' % (d))\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "filename = '*.las'\n",
    "# To define each .las file within each subdir as a string representation with forward slashes, use as_posix()\n",
    "# ** represents that any subdir string can be present between the base_dir and the filename (not using this because we don't want to include subdirs)\n",
    "flist = [p.as_posix() for p in base_dir.glob('./' + filename)]\n",
    "L.info('File list: %s' % (flist))\n",
    "flist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use las2las to write new VLR\n",
    "\n",
    "QT Modeler and other LiDAR processing software sometimes outputs VLR (variable length record) header information that does not adhere exactly to LAS standards. And sometimes, the data abstraction libraries like `PDAL` that undergird the tools we use on the Python side don't play nicely with those headers. Accordingly, sometimes it is necessary to use software that handles malformed headers gracefully like `lastools` to write headers that `PDAL` will accept. Here we use [`las2las`](https://downloads.rapidlasso.de/las2las_README.txt) to rewrite input LAS files with the correct VLR format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "las2lasstart = datetime.now()\n",
    "L.info('Using las2las to resolve any issues with malformed VLR (variable length record) from QT Modeler... (step 1 of 3)')\n",
    "i = 0\n",
    "for f in flist:\n",
    "    i += 1\n",
    "    L.info('Processing %s (%s of %s)' % (f, i, len(flist)))\n",
    "    bn = os.path.basename(f)\n",
    "    vlrcn = os.path.join(vlrcorrect_dir, bn)\n",
    "    an = os.path.join(archive_dir, bn)\n",
    "    subprocess.run([\n",
    "        '../bin/las2las',\n",
    "        '-i',\n",
    "        f,\n",
    "        '-epsg', '4326',\n",
    "        '-wgs84',\n",
    "        '-meter',\n",
    "        '-target_ecef',\n",
    "        '-target_epsg', '4326',\n",
    "        '-o',\n",
    "        vlrcn\n",
    "    ])\n",
    "    # move the file to the archive\n",
    "    L.info('Archiving to %s' % (an))\n",
    "    os.replace(src=f, dst=an)\n",
    "las2lastime = (datetime.now() - las2lasstart).seconds/60\n",
    "L.info('Finished las2las rewrite (%.1f min)' % (las2lastime))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new file list with VLR-corrected files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/shares/drp/pointcloud/vlrcorrect/Site7.las']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate new file list\n",
    "flist = [p.as_posix() for p in Path(vlrcorrect_dir).glob('./' + filename)]\n",
    "flist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use py3dtiles to tile point cloud data into web-ready chunks\n",
    "\n",
    "3dtiles is a format that breaks large datasets up into manageable chunks that can be easily downloaded and displayed at varying zoom levels. This conversion process computes and executes the tiling, then writes outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.0 % in 9 sec [est. time left: 0 sec]]]]]"
     ]
    }
   ],
   "source": [
    "processstart = datetime.now()\n",
    "L.info('Starting tiling process for %s file(s) (step 2 of 3)' % (len(flist)))\n",
    "i = 0\n",
    "for f in flist:\n",
    "    i += 1\n",
    "    tilestart = datetime.now()\n",
    "    L.info('Processing %s (%s of %s)' % (f, i, len(flist)))\n",
    "    L.info('Creating tile directory')\n",
    "    fndir = os.path.join(out_dir, os.path.splitext(os.path.basename(f))[0])\n",
    "    subprocess.run([\n",
    "        'py3dtiles',\n",
    "        'convert',\n",
    "        f,\n",
    "        '--out',\n",
    "        fndir,\n",
    "        '--overwrite'\n",
    "    ])\n",
    "    tiletime = (datetime.now() - tilestart).seconds/60\n",
    "    L.info('Done (%.1f min)' % (tiletime))\n",
    "processtime = (datetime.now() - processstart).seconds/60\n",
    "L.info('Finished tiling (%.1f min)' % (processtime))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge outputs of tiling runs on multiple input files\n",
    "\n",
    "This process takes note of the outputs of various tiling runs (put into subdirectories) and gathers the relative paths of all those outputs into one tileset JSON file.\n",
    "For example, consider this directory tree:\n",
    "\n",
    "```\n",
    "Sites_3dtiles\n",
    "├── Site4\n",
    "│   ├── r0.pnts\n",
    "│   ├── r1.pnts\n",
    "│   ├── r2.pnts\n",
    "│   ├── ...\n",
    "│   ├── r.pnts\n",
    "│   └── tileset.json\n",
    "├── Site5\n",
    "│   ├── r0.pnts\n",
    "│   ├── r1.pnts\n",
    "│   ├── r2.pnts\n",
    "│   ├── ...\n",
    "│   ├── r.pnts\n",
    "│   └── tileset.json\n",
    "└── tileset.json\n",
    "```\n",
    "Each subdirectory's `tileset.json` file would have pointers at and metadata for each of the tiles in the subdirectory, and the master `tileset.json` would point at each of those subdirectory tilesets in turn.\n",
    "\n",
    "The following code is designed to create the master tileset which points to all the various subdirectory tilesets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 tilesets to merge\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "L.info('Starting merge process in %s (step 3 of 3)' % (out_dir))\n",
    "mergestart = datetime.now()\n",
    "subprocess.run([\n",
    "    'py3dtiles',\n",
    "    'merge',\n",
    "    '--overwrite',\n",
    "    '--verbose',\n",
    "    out_dir\n",
    "])\n",
    "mergetime = (datetime.now() - mergestart).seconds/60\n",
    "L.info('Finished merge (%.1f min)' % (mergetime))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data in Cesium\n",
    "\n",
    "You can view the output tiles on a Cesium basemap! For steps for how to visualize the tiles with local Cesium, see [documentation here in pdg-info](https://github.com/julietcohen/pdg-info/blob/main/05_displaying-the-tiles.md#option-1-run-cesium-locally).\n",
    "\n",
    "Here is an example of the `cesium.js` file that ended up working for me (you will need your own access token):\n",
    "\n",
    "\n",
    "```javascript\n",
    "\n",
    "function start(){// Your access token can be found at: https://cesium.com/ion/tokens.\n",
    "\n",
    "  Cesium.Ion.defaultAccessToken = \"YOUR-TOKEN-HERE\"\n",
    "\n",
    "  const viewer = new Cesium.Viewer('cesiumContainer');\n",
    "\n",
    "  const imageryLayers = viewer.imageryLayers;\n",
    "\n",
    "  var tileset = new Cesium.Cesium3DTileset({\n",
    "    url: \"3dtiles/tileset.json\",\n",
    "    debugShowBoundingVolume: true,\n",
    "    debugShowContentBoundingVolume: false,\n",
    "    debugShowGeometricError: false,\n",
    "    debugWireframe: true\n",
    "  });\n",
    "\n",
    "  viewer.scene.primitives.add(tileset);\n",
    "\n",
    "  window.zoom_to_me = function(){\n",
    "    viewer.zoomTo(tileset);\n",
    "  }\n",
    "\n",
    "  tileset.readyPromise.then(zoom_to_me).otherwise(error => { console.log(error) });\n",
    "}\n",
    "\n",
    "start()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualization options\n",
    "\n",
    "The above `cesium.js` code will display the LiDAR data with its RGB values. However if the dataset doesn't have RGB values assigned, the points in the dataset will display black until you colorize them. There's some Cesium [learning material](https://cesium.com/learn/cesiumjs-learn/cesiumjs-3d-tiles-styling/#style-point-clouds) about point cloud stylizing, but here are a couple of other options to consider:\n",
    "\n",
    "- You can (sort of) [color points in discrete elevation bands](https://sandcastle.cesium.com/#c=tVdrb9s2FP0rhFegMmbLevmh1AnWeq8A3VLMbvdhHgpKom0iEimQlF0v8H/fJSk5cpygXdcECWxe8t5z7pPMFgu0pWRHBLpEjOzQjEhaFe4HI3OWndSsZ5wpTBkRy04P3S0ZQooIAZJ3gm9pRsRFo5gKghX5k4s8W9gjTre3ZIfuqyVbsi3AKZoTSRTgWWBXpoQRtxS0oIpuiXRxljkao8XHfoQ/LqyyYzggVIn8iHzN2R9E8kqkxF0JXryWcPA6c4JJHA01B61QcsrULOdVNt/gjLL1BapNIYSVIqzCinJ2gZSoSK/ZKfAnWlTF6/aBoN49mM9Dd8msi7V7LsQh20N4CiqJqzaEOauKpVrX6VrMwQDN1T4nKMGSZIgztCF0vVFIs0ckz2kpOc3qo4sNlQh+MUO4LAUHRoYJCDK0wbCBVhCvUpCUSi1P8RZSIWt1hHwXbBC0qgSwEQjv8B50TEC0XQMKO8f8QFYgycihTCe7kIivUM7ZmqoqIz2UA7r+1jVKBRcEUcZwWgnIv5HV3iQk5QW55xG46N3N/HpxffP7x9dv5jdv3y9+Mo6hMOgnVKEtzittzBiRkCZgsdvQdKNPMa6QrFYrmlLg13J3xaG0dIxkinNi0Y6hA0I7jsBjiRRHtID4bYk9jgVph2jGi7ICB0oi+jY2x0Q0DnHLbPbuvYl9gW+BrUJ4i2mOE8gnQBjqJrkmM0lFc9UHl6DGBE0AoB2OBtPal43rOhHCQEhIpTUExIGZ2mv1VjPNbK4um7Wb8Irp8p6XkGvi2ly+arRkJVY4JTMsFF8LXEJwQbdptZbUNJIWwBZmzgla15h7xJRbx+kSea73GKYx9gSg4vdwj9juHu1lVCrMUrLgc3vs1KCxELoFXjNTps5DfNut6Bgxm63Lp4aO6dRm7GRkBcNQtmaHdfkCLTs5YWu1cV7cnRX5oYv6cAB9f869PUoQSnnORct4yiGXutcB8a9GiOBr58WdBT6gKYog2no8w8zW+s5LLjBbk5fdZefv3pNaw4dae6h3vvuM1uihVk6LzyGNH+qke8we0dGT9+Qc9L6yxptz9ZeDnbyvjtcLNNTP+V73H0aMQklAlwt9y+jZpVsqpWrvwjVkL54UF0Rgd5XvF/w+tVJRVs/4di0ca8qxB/1gNPYmvjvy42E4mkzC2ot+FMTeOIrc2B/74SQK43ojGoZeHPmuF/lDP479WIvtvcSFHmY1aEOEwmj7PA0A9NxxOJz4oReNh74Xe5NjPD13FMDlB/KRF4aTYBS0toIoHof+MI7C4RB2/cBuNTdlVX4BsBeP41EcRqNJFAVh4I97rc1oBO6PRwA+CoajY4A09mTiRcDYDzxgF7eBbQ9k+hYxvnt1cju9ztS06FVj5QcY41wo/QZwXHegSFHCnUTkIKnSW2joVEo7LfTPd4rzPIGxcXdfawlOb9dCD8oLJNYJdqKgh5o/4HivDe8GeJOY10JUfmqJEy7gduoLeEpU8nTzcAZNGUz5NgEoTkXhturjnK7B14JmWU7OUfuKQzKCE+RmK+FK8eJ09xwaRrK5RlvgK3jS9Xf12Ep4nj1Unw7a8Z5mdItodvnIixClOZYSdlZVns/pP9C9V9MBnD9Tzbl5c92A4zne62Mb/+qtFbquOx3A8nHN2hFQaVhOlb5rr+4dmqqEZ/uWQIvEyVpLsiNdGxMwOdMCCk8K+6Ba7EsipwOVndoaPDD2qPGrX0xBnWnbzaktAQUAOpAbkt4m/BNEMMMKw9uHZY2YQE3a2jTB/Doub/kOfSBrYifLE5xOJSD7Txzhqvi4PUK00nMk+lXMfyPQUMVzky8MynPw/xXa6rnZbwDjObi/gbeqbkj5TYo4aaz9jzq+0f+wDN6ztO5T8m36i2uzX0ALlieTBdat0dOeV/8C)\n",
    "- Color points by [proximity to a point in xyz space](https://sandcastle.cesium.com/#c=dVTbjts2EP0VwghgCVBp6i4lziKOu0WMul1j7TQvAgKaorNsaNIgKW3dhf+9pC5OnSB6sDzDmXNm5gw1m20kEwYsuWxqsD+DjZIHCDbUUAUWnFMRgKXkzXHPMPgoWEuVZuYMHuVeGkY0WOM9BFuChWDiiwNYcPo3FrWSYKckIZIzYE3wBzaUgSWTBCvOKKxEixVoGX22RG+BoM9gSTVrjvCvzudNSWcupTCYCaqmAXipBLCPLU1Zl620ZbXNfj1mEkUtyyepeL3rYzy/Ehf/TSV6uidbCf+eb2vTqNieMKH3LRXmQx/k9bVBTaig0DbYYu2QBgyoqVmJU2MWxDApvEMj+j/UYfhjrY7VdmwsFRaW9wb0xMjXjbTzvObB02A6JpdPpNCSU8jlF++K4w4vwc/q351PFK7vf9t9Xq5Xy9+/da/NmVNbw1BaTQ92rtqOb3B0TqYNFoRa75RwfDx5o8d79bJ52K52q4c/Py/ebx/WH3f3toiWkthLEhRmZQmTMInLMgyTAERRisIIZqjMwyxMUBqAJC3TJA5hEucoTKOi9H0wA1EKUQCQ+wkh8qd9LZdg7J9Lp/D0yP7xOsOrJmfKuXyuJn4ARpeidWe/ehnrvTioy7V5wzi1kt1K37/iX3f9ofcCGsWv67SS4pFq2ShC4UHJ40I7zWsvzJIo9EG3VwMsHGf7E/CtO/a6IJd1uwWKHa3mLdUQ17U3IA6y3e7gkSrsFs9dEe8qozZMYLc0r2/ox23p5cmTBGaJFSiNR3lSK0WI8sIKhtJo0CdCMM6TvEiSOPYHEaRidq9+pPhAcW1v/YYZ8vQoOfdSS5HlcVygFMVlnuYB+AXBKM8ylIdpXMRlUWQByGBUhJa0yNMEIVSk327pJJjMuzHd9dTv2PEklXG6eBDODD2euL3jerZvyFc7d6K7SzmfjUnzmrWA1W+ryXffj2oC7EJrbU8ODedb9i+tJnfzmY2/SeOya+rBfuk4PruQp/Bu3TshhPOZNX/MMlLyPVb/Q/wP)\n",
    "- And in the future, Cesium plans on [making elevation accessible to a custom shader](https://github.com/CesiumGS/cesium/issues/9735). There is also a more detailed discussion of this in [CesiumGS/3d-tiles#603](https://github.com/CesiumGS/3d-tiles/issues/603).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipToFP_PR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
